# idioms.r
#R idioms that I can't seem to remember if I don't use it for a couple months.


setwd("s:/landau/python/R")
in RStudio, ALWAYS ALWAYS ALWAYS browse to the directory you want 
AND THEN remember to More | Set working directory.  

source("scriptfile.r")

dat <- data.frame(read.table("s:/landau/python/dev/preservationsimulation/shelf/q0-alldata-medians-00.txt", header=TRUE))
read.csv    # comma sep
read.delim  # tab sep

rm(dat)     # delete data object

for (var in c(val1,val2,val3)) { statements }

c(rep("string",ntimes))

#factors
fdocsize <- factor(dd$docsize)
fberid <- factor(dd$berid)
fcopies <- factor(dd$copies)

#levels
ldocsize <- levels(factor(dd$docsize))
ldocsize <- levels(fdocsize)
lberid <- levels(fberid)
lcopies <- levels(fcopies)

length(l.copies)

# 2:5 is the list 2,3,4,5, same as c(2,3,4,5)
# x[c(2,3,4)] is x[2:4] is columns 2,3,4 of all the data, 
i.e., vars 2,3,4 (columns) 
across all instances (rows)
x[rownum,]  # that row
x[,colnum]  # that column

rep(thing,count)
seq(from, to, by, length, along)
rep(x, times, length)       

cbind(thing1,thing2)
rbind(thing1,thing2)
cbind(dat$copies,dat$lifem)     int vectors
foo<-data.frame(cbind(dat$copies,dat$lifem))

table(factor) gives count of vector items at levels of factor
table(factor1,factor2) gives counts of the intersections of the
two factors
table(factor1,factor2,factor3) gives a set of tables of 
those like table(factor1,factor2),one for each level of factor3.  

#datn <- cbind(dat[,4],dat[,5],dat[,6],dat[,9])
#datn <- cbind(dat$docsize,dat$berid,dat$copies,dat$lost)
datn = data.frame(dat$docsize,dat$berid,dat$copies,dat$lost)
        # creates colnames dat.docsize,dat.berid,dat.copies,dat.lost !

summary(vect)
fivenum(vect)
# var <- function(args) {statements}    # returns last expression evaluated
trimean <-  function(vect) { foo = fivenum(vect); 0.5*foo[3] + 0.25*foo[2] + 0.25*foo[4]}
trimean(datn[1:11,4])

scale(data,scale=T) #centers around the mean and scales by the sd)
colMeans(x, na.rm = FALSE, dims = 1)

d5 = data.frame(datn[datn$dat.docsize==5,])
d50 = data.frame(datn[datn$dat.docsize==50,])
d500 = data.frame(datn[datn$dat.docsize==500,])
d5000 = data.frame(datn[datn$dat.docsize==5000,])

apply
lapply(vectlist,"funcname",moreargs)
vapply
sapply
tapply
aggregate
plyr
ddply
aggregate(d5, by=list(d5$dat.copies,d5$dat.berid),FUN=median)

f.d5m.berid = factor(d5aggm$dat.berid)
l.d5m.berid <- levels(f.d5m.berid)
for (bb in l.d5m.berid){print(d5aggm[d5aggm$dat.berid==bb,])}

d5aggm <- aggregate(d5, by=list(d5$dat.copies,d5$dat.berid),FUN=median)
d50aggm <- aggregate(d50, by=list(d50$dat.copies,d50$dat.berid),FUN=median)
d500aggm <- aggregate(d500, by=list(d500$dat.copies,d500$dat.berid),FUN=median)
d5000aggm <- aggregate(d5000, by=list(d5000$dat.copies,d5000$dat.berid),FUN=median)

trimean <-  function(vect) { foo = fivenum(vect); ans <- 0.5*foo[3] + 0.25*foo[2] + 0.25*foo[4]}

d5aggt <- aggregate(d5, by=list(d5$dat.copies,d5$dat.berid),FUN=trimean)
d50aggt <- aggregate(d50, by=list(d50$dat.copies,d50$dat.berid),FUN=trimean)
d500aggt <- aggregate(d500, by=list(d500$dat.copies,d500$dat.berid),FUN=trimean)
d5000aggt <- aggregate(d5000, by=list(d5000$dat.copies,d5000$dat.berid),FUN=trimean)


for (bb in levels(factor(d5aggm$dat.berid))){print(d5aggm[d5aggm$dat.berid==bb,])}
for (bb in levels(factor(d50aggm$dat.berid))){print(d50aggm[d50aggm$dat.berid==bb,])}
for (bb in levels(factor(d500aggm$dat.berid))){print(d500aggm[d500aggm$dat.berid==bb,])}
for (bb in levels(factor(d5000aggm$dat.berid))){print(d5000aggm[d5000aggm$dat.berid==bb,])}

for (bb in levels(factor(d5aggt$dat.berid))){print(d5aggt[d5aggt$dat.berid==bb,])}
for (bb in levels(factor(d50aggt$dat.berid))){print(d50aggt[d50aggt$dat.berid==bb,])}
for (bb in levels(factor(d500aggt$dat.berid))){print(d500aggt[d500aggt$dat.berid==bb,])}
for (bb in levels(factor(d5000aggt$dat.berid))){print(d5000aggt[d5000aggt$dat.berid==bb,])}

for (ds in levels(factor(dat$docsize))) {tmp<-dat[dat$docsize==ds,]}

#for (ds in levels(factor(dat$docsize))){
#    tmp <- data.frame(datn[datn$dat.docsize==ds,])
#    #aggm <- aggregate(tmp, by=list(tmp$copies,tmp$berid), FUN=median)
#}

datn = data.frame(dat$docsize,dat$berid,dat$copies,dat$lost)
for (ds in levels(factor(datn$dat.docsize))){
    tmp <- data.frame(datn[datn$dat.docsize==ds,])
    aggm <- aggregate(tmp, by=list(tmp$dat.copies,tmp$dat.berid), FUN=median)
    aggt <- aggregate(tmp, by=list(tmp$dat.copies,tmp$dat.berid), FUN=trimean)
#    print(aggm)
#    print(aggt)
    for (bb in levels(factor(aggm$dat.berid))) {print(aggm[aggm$dat.berid==bb,])}
}

for (ds in levels(factor(datn$dat.docsize))){
    tmp <- data.frame(datn[datn$dat.docsize==ds,]);
    for (be in levels(factor(tmp$dat.berid))) {
        tmp2 <- tmp[tmp$dat.berid==be,]
        print(ds)
        print(be)
        tmp3 = aggregate(tmp2, by=list(tmp2$dat.copies), FUN=median)
        print(tmp3)
    }
}

trimean <-  function(vect) { foo = fivenum(vect); ans <- 0.5*foo[3] + 0.25*foo[2] + 0.25*foo[4]}

# Summary table with medians.
summ <- data.frame(cbind(0,0,1,2,3,4,5,8,10,14,16,20))
colnames(summ) <- c("docsize","berid","c1","c2","c3","c4","c5","c8","c10","c14","c16","c20")
datn = data.frame(dat$docsize,dat$berid,dat$copies,dat$lost)
colnames(datn)<-c("ds","be","lost")
for (ds in levels(factor(datn$dat.docsize))){
    tmp <- data.frame(datn[datn$dat.docsize==ds,]);
    for (be in levels(factor(tmp$dat.berid))) {
        tmp2 <- tmp[tmp$dat.berid==be,]
        tmp3 = aggregate(tmp2, by=list(tmp2$dat.copies), FUN=median)
        newrow <- c(ds,be,tmp3$dat.lost)
        if (length(newrow) < length(colnames(summ)))
        {
            filler <- rep(0,length(colnames(summ)) - length(newrow))
            #print(c(length(filler),"=>",filler))
            #print(c(length(newrow),"=>",newrow))
            newrow <- c(newrow,filler)
        }
        print(newrow)
        summ <- rbind(summ,newrow)
    }
}
summ <- summ[-1,]
rownames(summ) <- NULL

# New columns can be added to data frame, by assigning to a
# currently non-existent column name (this works for lists too)

thue2 <- subset(thuesen, blood.glucose < 7)

thue3 <- transform(thue2, log.gluc = log(blood.glucose))

sink("output.txt")
print(...)
cat(...)
sink()
or 
cat("Hello",file="outfile.txt",sep="\n")
cat("World",file="outfile.txt",append=TRUE)
or 
txt <- "Hello\nWorld"
writeLines(txt, "outfile.txt")

# direct output to a file
sink("myfile", append=FALSE, split=FALSE)
 . . . 
# return output to the terminal
sink()

# starts up an external editor
file.show("filename.txt")

sapply(summ,mode)   # are the columns numeric or character?
sapply(summ,class)  # similarly

numeric(N)  # numeric vector of length n
as.numeric(something)   # convert all items of vector to numeric

# Summary table with medians.
#summ <- data.frame(cbind(0,0,1,2,3,4,5,8,10,14,16,20))
summ <- data.frame(rbind(numeric(12)))
colnames(summ) <- c("docsize","berid","c1","c2","c3","c4","c5","c8","c10","c14","c16","c20")
datn = data.frame(dat$docsize,dat$berid,dat$copies,dat$lost)
for (ds in levels(factor(datn$dat.docsize)))
{
    tmp <- data.frame(datn[datn$dat.docsize==ds,]);
    for (be in levels(factor(tmp$dat.berid))) 
    {
        tmp2 <- tmp[tmp$dat.berid==be,]
        tmp3 = aggregate(tmp2, by=list(tmp2$dat.copies), FUN=median)
        newrow <- c(ds,be,tmp3$dat.lost)
        if (length(newrow) < length(colnames(summ)))
        {
            filler <- rep(0,length(colnames(summ)) - length(newrow))
            #print(c(length(filler),"=>",filler))
            #print(c(length(newrow),"=>",newrow))
            newrow <- c(newrow,filler)
        }
        print(newrow)
        summ <- rbind(summ,as.numeric(newrow))
    }
}
summ <- summ[-1,]
rownames(summ) <- NULL

cat("foo","bar")    # space between but no quotes and no \n
cat("label",value,"\n")

sink( ) will not redirect graphic output. 
To redirect graphic output use one of the following functions. 
Use dev.off( ) to return output to the terminal.
Function 	Output to
pdf("mygraph.pdf") 	pdf file
win.metafile("mygraph.wmf") 	windows metafile
png("mygraph.png") 	png file
jpeg("mygraph.jpg") 	jpeg file
bmp("mygraph.bmp") 	bmp file
postscript("mygraph.ps") 	postscript file

Use a full path in the file name to save the graph 
outside of the current working directory. 

apply(dataframe, 1or2, function)    # 1 by rows, 2 by columns
sapply(1:3, function(x) x^2)
#[1] 1 4 9
lapply(1:3, function(x) x^2)
#[[1]]
#[1] 1
#
#[[2]]
#[1] 4
#
#[[3]]
#[1] 9
unlist(lapply(1:3, function(x) x^2))
#[1] 1 4 9
sapply(1:3, function(x, y) mean(y[,x]), y=m)
#[1] -0.02664418  1.95812458  4.86857792

apply()
eapply(environment, function)      # environment var
lapply(list, function)  # return list
mapply()    # multivariate version of sapply()?
rapply()    # recursive?
sapply(list, function)
tapply(list, index, function)   # for ragged arrays?
vapply(list, function, outputtemplate)

by(columns, factor, function)
replicate(ntimes, function)

sweep
column
row

commandArgs <- function() 1:3  or 
commandArgs <- function() c("foo", "bar")
source("testcli0.r")
where testcli0.r is 
print(commandArgs())



foo<-dat[dat$seed==919028296,]
# just to shorten things, but could use 
foo<-dat

# this is right
bar<-data.frame(foo$copies,foo$lifem,foo$lost,
    foo$shockfreq,foo$shockimpact,
    foo$shockspan,foo$shockmaxlife)

# but Micah's way is simpler
# Set up namesets for dependent, independent, ignored vars.
#  Many of the columns are not relevant to data analysis, only tracking.
allVarNames <- colnames(sims.merged.df)
ignoreVarNames <- c("timestamp","seed","walltime","cputime","logfilename",
    "logfilesize","instructionfilename","todaysdatetime","extractorversion",
    "cpuinfo","mongoid")
resultVarNames <- c("docslost","docsrepairedmajority","docsrepairedminority",
    "lost","nshocks","nglitches","deadserversactive","deadserversall",
    "docsokay","auditmajority","auditminority","auditlost","auditrepairs",
    "auditcycles")
coreResultVarNames<- c("docslost","docsrepairedmajority","docsrepairedminority")
paramVarNames<- setdiff(setdiff(allVarNames, resultVarNames), ignoreVarNames)
testVarNames<-c("copies", "lifem")
nonIgnoreVarNames<-setdiff(allVarNames, ignoreVarNames)
# Select, group, and aggregate.
sims.selected.df <- sims.merged.df[nonIgnoreVarNames]

# sooooo, 
lNamesIWant <- c("copies","lifem","mdmlosspct",
                "shockfreq","shockimpact","shockmaxlife","shockspan")
shockresults <- results[lNamesIWant]

c1<-bar$foo.shockfreq
f1<-levels(factor(c1))
for (s1 in f1) {d1<-data.frame(bar[bar$foo.shockfreq==s1,])}
# gets all rows with the last value in f1 = 30000 hrs

c2<-bar$foo.copies
f2<-levels(factor(c2))
for (s2 in f2) {d2<-data.frame(d1[bar$foo.copies==s2,])}
# gets all rows with the last value in f2 = 5 copies

# list with named items
vars <- list(a = 1:10, b = rnorm(100), d = LETTERS)
vars[["a"]]

midmean <-  function(vect)  { ans <- mean(vect,trim=0.25,na.rm=TRUE); ans }
library(plyr)
x <- ddply(foo, .(shockfreq, shockimpact,shockspan,lifem,copies), summarise,(lostdocs = midmean(lost)))
y = arrange(x,lifem,shockspan)
z = arrange(x,shockspan,lifem)
# the midmeans seem to be wrong, but at least it didn't fail horribly.

dat <- data.frame(read.table(sInputFilename, header=TRUE))
foo<-dat[!dat$serverdefaultlife==50000,]
write.table(foo, file="GiantOutput_glitchvslife_20170522_edited_01.txt", row.names=FALSE, quote=FALSE)

    # E D I T M E :  C O L U M N S   T O   B E   G R O U P E D    
    column.list <- .(
         glitchfreq
        ,glitchimpact
        ,glitchmaxlife
        ,lifem
        ,copies
        ,serverdefaultlife
    )
    # E D I T M E :  C O L U M N   L A B E L S   F O R   H U M A N S 
    column.labels <- c(
         "glitch frequency (hrs)"
        ,"glitch impact (pct)"
        ,"glitch duration (hrs)"
        ,"sector half-life (megahours)"
        ,"# of copies"
        ,"server default half-life"
        ,"lost midmean"
        ,"median"
        ,"Nsamples"
    )
    # E D I T M E :  C O L U M N   L A B E L S   F O R   P R I N T I N G 
    column.shortlabels <- c(
         "glitchfreq"
        ,"impact"
        ,"duration"
        ,"lifem"
        ,"copies"
        ,"svrdeflife"
        ,"lost midmean"
        ,"median"
        ,"Nreps"
    )
    summ.first <- ddply(dat, column.list, summarise
        ,"lost midmean"=midmean(lost)
        ,median=median(lost)
#        ,mean=mean(lost)
        ,Nreps=length(lost)
    )
    head.reorder5 <- "Summary losses (midmeans), reordering 5: svrhl glitchdur impact copies life freq"
    summ.reorder5 <- arrange(summ.first
                ,serverdefaultlife
                ,glitchmaxlife
                ,glitchimpact
                ,copies
                ,lifem
                ,glitchfreq
                )
    fnPageHeading()
    cat("\n\n", head.reorder5, "\n\n")
    colnames(summ.reorder5) <- column.shortlabels
    print(summ.reorder5)

trimean <-  function(vect)  { foo <- fivenum(vect); ans <- 0.5*foo[3] + 0.25*foo[2] + 0.25*foo[4]; ans }
midmean <-  function(vect)  { ans <- mean(vect,trim=0.25,na.rm=TRUE); ans }

# f n b C h e c k F i l e 
# If the file exists, return true; else spit out an error message and false.  
fnbCheckFile <- function(filename){
    if (!file.exists(filename))
    {
        cat("Error, file not found: ", filename, "\n")
        result <- FALSE
    }
    else
    {
        result = TRUE
    }
    return(result)
}
# If you need to defeat name scoping for a few variables, ...
# Expose the data so I can at least see them in R Studio for debugging.
assign("dat", dat, envir=globalenv())
assign("datn", datn, envir=globalenv())

# Absurd hack in here to make lifem print reasonably.
#  Increase the penalty for printing in scientific 
#  (exponential) format, and limit the number of digits
#  so that there are no places after the radix point.  
options("scipen"=100, "digits"=1)
# End of absurd hack.  

source(sAnalyzeFilename)

# Unwind any remaining sink()s to close output files.  
# Particularly important in case of errors.  
while (sink.number() > 0) {sink()}

# How do we tabulate from long lists of numbers to a publishable table 
#  also usable for plotting.
losstable <- data.frame(xtabs(mdmlosspct ~ copies + lifem, results))
library(reshape2)
losstable <- dcast(results, copies ~ lifem, FUN=identity(basicdata$lossp))
losstable <- dcast(results, copies~lifem,  
                    fun.aggregate=max, value.var="mdmlosspct")
losstable <- dcast(results, copies~lifem,  
                   FUN=identity(results$mdmlosspct), value.var="mdmlosspct")
# dcast works but is fragile.
# I can't get xtabs to work at all, creates a long list, not wide table.  

losstable <- with(results, tapply(mdmlosspct, list(copies, lifem), FUN=identity))
table.noaudit <- with(basicdata, tapply(lossp, list(copies, lifem), FUN=identity))

basictable <- dcast(basicdata, copies~lifem, value.var="lossp", median)
shocktable <- dcast(shockresults, copies~lifem, value.var="mdmlosspct", median)

pathnames <- list.files(pattern="[.]R$", path="R/", full.names=TRUE);
sapply(pathnames, FUN=source);
    or
sapply(list.files(pattern="[.]R$", path="R/", full.names=TRUE), source);

# My crappy way:
# T A B U L A T E   D A T A 
# Tabulate columns by copies and sector lifetime.
tbl.auditannually <- data.frame(with(dat.auditannually, 
            tapply(mdmlosspct, list(copies, lifem), FUN=identity)))
# Re-form the data into a table for printing.  
foo<-(with(dat.auditannually, 
       tapply(mdmlosspct, list(copies, lifem), FUN=identity)))
foo2<-cbind(as.numeric(levels(factor(results$copies))), foo)
tbl2<-data.frame(foo2)
colnames(tbl2)<-c("copies",as.numeric(colnames(foo2[,2:ncol(foo2)])))

# Micah found the easy and reliable way:
library(reshape2)
bar.small <- dat.auditannually[,c("copies", "lifem", "mdmlosspct")]
bar.melted <- melt(bar.small, id=c("copies", "lifem"))
bar.recast <- dcast(bar.melted, copies~lifem)

# an infix concatenation operator for strings
`%+%` <- function(a,b) paste0(a,b)

# Absurd hack here to make large numbers print reasonably.
#  Increase the penalty for printing in scientific 
#  (exponential) format, and limit the number of digits
#  so that there are no or few places after the radix point.  
options("scipen"=100, "digits"=1)
# End of absurd hack.  

# Enable printing wide tables.
options("width"=120)



